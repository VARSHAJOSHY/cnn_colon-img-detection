{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:24.364508Z",
     "iopub.status.busy": "2022-03-25T23:40:24.364105Z",
     "iopub.status.idle": "2022-03-25T23:40:24.874794Z",
     "shell.execute_reply": "2022-03-25T23:40:24.874043Z",
     "shell.execute_reply.started": "2022-03-25T23:40:24.364442Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:25.197831Z",
     "iopub.status.busy": "2022-03-25T23:40:25.197259Z",
     "iopub.status.idle": "2022-03-25T23:40:25.214199Z",
     "shell.execute_reply": "2022-03-25T23:40:25.213301Z",
     "shell.execute_reply.started": "2022-03-25T23:40:25.197794Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0ca682312308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import pathlib\n",
    "\n",
    "\n",
    "print('All libraries are imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:25.843533Z",
     "iopub.status.busy": "2022-03-25T23:40:25.843267Z",
     "iopub.status.idle": "2022-03-25T23:40:25.850702Z",
     "shell.execute_reply": "2022-03-25T23:40:25.849822Z",
     "shell.execute_reply.started": "2022-03-25T23:40:25.843504Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 32 #image size 32*32\n",
    "workers = 2  # Number of workers required for data loading\n",
    "ngpu = 1 # Number of GPUs available. Use 0 for CPU mode.\n",
    "num_epochs=25\n",
    "batch_size = 64  #number of samples in each batch.\n",
    "#train data path \n",
    "train_rootpath=\"/kaggle/input/deep-learning-for-msc-coursework-2022/train/train/\"\n",
    "#test data path\n",
    "test_rootpath=\"/kaggle/input/deep-learning-for-msc-coursework-2022/test/\"\n",
    "# Select the device to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "shuffle=True # data to be shuffled whenever needed\n",
    "manualSeed = 499 # Set random seed for reproducibility\n",
    "#lr=0.001\n",
    "lr=0.000075\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Augmentation**\n",
    "To improve model accuracy, performed various augmentation techniques on images, like converted images to tensors. rotate the images to 45 degree randomly. Normalize the image to makes model training stable and fast and better convergence. Increased image brightness by 0.6. Random images are horizontally flipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:26.516029Z",
     "iopub.status.busy": "2022-03-25T23:40:26.515455Z",
     "iopub.status.idle": "2022-03-25T23:40:26.521257Z",
     "shell.execute_reply": "2022-03-25T23:40:26.520405Z",
     "shell.execute_reply.started": "2022-03-25T23:40:26.515988Z"
    }
   },
   "outputs": [],
   "source": [
    "#image augmentation; convert image to tensors.Normalizing an image to makes model training stable and fast\n",
    "transform = transforms.Compose([\n",
    "                            transforms.ColorJitter(brightness=0.6),\n",
    "                            transforms.ToTensor(),\n",
    "                            #transforms.Resize((64,64)),\n",
    "                            transforms.RandomHorizontalFlip(p=0.5),\n",
    "                            transforms.Normalize((0.5),(0.5)),\n",
    "                            transforms.RandomRotation(degrees=45)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Training Dataset**\n",
    "Cells are not distributed equally: 'Cancer': 500, 'Connective': 500, 'Immune': 500, 'Normal': 200. 500 number of occurrences found with cell types - Cancer, Connective, Immune; however Normal cells are very less in number. This resulted unbalanced training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:27.206586Z",
     "iopub.status.busy": "2022-03-25T23:40:27.206061Z",
     "iopub.status.idle": "2022-03-25T23:40:29.822295Z",
     "shell.execute_reply": "2022-03-25T23:40:29.821539Z",
     "shell.execute_reply.started": "2022-03-25T23:40:27.206552Z"
    }
   },
   "outputs": [],
   "source": [
    " # load the training dataset\n",
    "train_dataset = dset.ImageFolder(root=train_rootpath,transform=transform)\n",
    "\n",
    "idx2class = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
    "\n",
    "def get_class_distribution(dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for element in dataset_obj:\n",
    "        y_lbl = element[1]\n",
    "        y_lbl = idx2class[y_lbl]\n",
    "        count_dict[y_lbl] += 1\n",
    "            \n",
    "    return count_dict\n",
    "\n",
    "train_data_dict=get_class_distribution(train_dataset)\n",
    "print(train_data_dict)\n",
    "names = list(train_data_dict.keys())\n",
    "values = list(train_data_dict.values())\n",
    "\n",
    "plt.bar(range(len(train_data_dict)), values, tick_label=names)\n",
    "plt.title(\"Training Set label distribution : Before splitting\")\n",
    "plt.xlabel(\"Cell Type\")\n",
    "plt.ylabel(\"Number of cells\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing Training set into training and validation set** Randomly splitted training set into 2 (90% training set and 10% validation set). Training set contains 1530 and validation set contains 170 cell images. Dataloaders are initialised. Here shuffle=true is not used because I already used sampler and sampler and shuffle are mutually exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:29.824369Z",
     "iopub.status.busy": "2022-03-25T23:40:29.823815Z",
     "iopub.status.idle": "2022-03-25T23:40:29.838273Z",
     "shell.execute_reply": "2022-03-25T23:40:29.836898Z",
     "shell.execute_reply.started": "2022-03-25T23:40:29.824325Z"
    }
   },
   "outputs": [],
   "source": [
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.1 * num_train))\n",
    "\n",
    "if shuffle:\n",
    "    np.random.seed(manualSeed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=workers\n",
    "    )\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=workers\n",
    "    )\n",
    "print(\"Size of train set :\", len(train_dataloader.sampler))\n",
    "print(\"Size of validation set :\", len(val_dataloader.sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:29.842458Z",
     "iopub.status.busy": "2022-03-25T23:40:29.841909Z",
     "iopub.status.idle": "2022-03-25T23:40:29.854955Z",
     "shell.execute_reply": "2022-03-25T23:40:29.854104Z",
     "shell.execute_reply.started": "2022-03-25T23:40:29.842421Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_class_distribution_loaders(dataloader_obj, dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "\n",
    "    for _,label_id in dataloader_obj:\n",
    "        for idx in label_id:\n",
    "            y_idx = idx.item()\n",
    "            y_lbl = idx2class[y_idx]\n",
    "            count_dict[str(y_lbl)] += 1\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of Labels in Training and Validation Set** Validation set also contains unbalanced data as in Training set. Number of occurrences in each label except 'Normal' is more or less similar. 'Cancer': 48, 'Connective': 54, 'Immune': 50, 'Normal': 18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:29.861630Z",
     "iopub.status.busy": "2022-03-25T23:40:29.860488Z",
     "iopub.status.idle": "2022-03-25T23:40:32.338568Z",
     "shell.execute_reply": "2022-03-25T23:40:32.337680Z",
     "shell.execute_reply.started": "2022-03-25T23:40:29.861591Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_dict = get_class_distribution_loaders(train_dataloader, train_dataset)\n",
    "val_data_dict = get_class_distribution_loaders(val_dataloader, train_dataset)\n",
    "print(train_data_dict)\n",
    "print(val_data_dict)\n",
    "print()\n",
    "\n",
    "train_names = list(train_data_dict.keys())\n",
    "train_values = list(train_data_dict.values())\n",
    "\n",
    "val_names = list(val_data_dict.keys())\n",
    "val_values = list(val_data_dict.values())\n",
    "\n",
    "fig, (axes1,axes2) = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "axes1.bar(range(len(train_data_dict)), train_values, tick_label=train_names, color=[ 'red', 'green', 'blue', 'cyan'])\n",
    "axes1.set_title(\"Training Set label distribution : After splitting\")\n",
    "axes1.set_xlabel(\"Type of Cell\")\n",
    "axes1.set_ylabel(\"Number of cells\")\n",
    "\n",
    "axes2.bar(range(len(val_data_dict)), val_values, tick_label=val_names, color=[ 'red', 'green', 'blue', 'cyan'])\n",
    "axes2.set_title(\"Validation Set label distribution : After splitting\")\n",
    "axes2.set_xlabel(\"Type of Cell\")\n",
    "axes2.set_ylabel(\"Number of cells\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting some of the training images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:32.681186Z",
     "iopub.status.busy": "2022-03-25T23:40:32.680478Z",
     "iopub.status.idle": "2022-03-25T23:40:33.389269Z",
     "shell.execute_reply": "2022-03-25T23:40:33.387753Z",
     "shell.execute_reply.started": "2022-03-25T23:40:32.681144Z"
    }
   },
   "outputs": [],
   "source": [
    "real_batch = next(iter(train_dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical analysis of training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:35.200747Z",
     "iopub.status.busy": "2022-03-25T23:40:35.200475Z",
     "iopub.status.idle": "2022-03-25T23:40:35.433841Z",
     "shell.execute_reply": "2022-03-25T23:40:35.432872Z",
     "shell.execute_reply.started": "2022-03-25T23:40:35.200717Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiterator = iter(train_dataloader)\n",
    "images,labels = dataiterator.next()\n",
    "print(torch.min(images),torch.max(images))\n",
    "print(labels.shape)\n",
    "print(images.shape)\n",
    "#Finding unique labels in train dataset\n",
    "root=pathlib.Path(train_rootpath)\n",
    "tr_classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "tr_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting some of the Validation images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:38.201401Z",
     "iopub.status.busy": "2022-03-25T23:40:38.200495Z",
     "iopub.status.idle": "2022-03-25T23:40:38.864357Z",
     "shell.execute_reply": "2022-03-25T23:40:38.863656Z",
     "shell.execute_reply.started": "2022-03-25T23:40:38.201359Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "real_batch = next(iter(val_dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Validation Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical Analysis of Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:40.640874Z",
     "iopub.status.busy": "2022-03-25T23:40:40.640088Z",
     "iopub.status.idle": "2022-03-25T23:40:40.937526Z",
     "shell.execute_reply": "2022-03-25T23:40:40.936556Z",
     "shell.execute_reply.started": "2022-03-25T23:40:40.640802Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiterator = iter(val_dataloader)\n",
    "images,labels = dataiterator.next()\n",
    "print(torch.min(images),torch.max(images))\n",
    "print(labels.shape)\n",
    "print(images.shape)\n",
    "val_names #unique labels in validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting some of the Test Set Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:41.970613Z",
     "iopub.status.busy": "2022-03-25T23:40:41.970314Z",
     "iopub.status.idle": "2022-03-25T23:40:42.446189Z",
     "shell.execute_reply": "2022-03-25T23:40:42.445552Z",
     "shell.execute_reply.started": "2022-03-25T23:40:41.970579Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = dset.ImageFolder(root=test_rootpath,transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle = True)\n",
    "real_batch = next(iter(test_dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Test Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Network Architecture**  I craeted 7 convolutional block with batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:42.963159Z",
     "iopub.status.busy": "2022-03-25T23:40:42.962867Z",
     "iopub.status.idle": "2022-03-25T23:40:42.985870Z",
     "shell.execute_reply": "2022-03-25T23:40:42.984782Z",
     "shell.execute_reply.started": "2022-03-25T23:40:42.963125Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=4):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        # Defining first 2D convolution layer\n",
    "        #((w-f+2P)/s) +1\n",
    "        #Input shape= (64,3,32,32)\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #calculation (32-3+2*1)/1 +1 = 32\n",
    "        #Shape= (256,12,32,32)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)# added batch normalization\n",
    "        #Shape= (64,12,32,32)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (64,12,32,32)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size by factor 2\n",
    "        #Shape= (64,12,16,16)\n",
    "        \n",
    "        # Defining second 2D convolution layer\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (64,20,16,16)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (64,20,16,16)\n",
    "        \n",
    "        # Defining third 2D convolution layer\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (64,32,16,16)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)# added batch normalization\n",
    "        #Shape= (64,32,16,16)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (64,32,16,16)  \n",
    "        \n",
    "         # Defining fourth 2D convolution layer\n",
    "        self.conv4=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (64,64,16,16)\n",
    "        self.bn4=nn.BatchNorm2d(num_features=64)# added batch normalization\n",
    "        #Shape= (64,64,16,16)\n",
    "        self.relu4=nn.ReLU()\n",
    "        #Shape= (64,64,16,16) \n",
    "        \n",
    "        # Defining fifth 2D convolution layer\n",
    "        self.conv5=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (64,128,16,16)\n",
    "        self.bn5=nn.BatchNorm2d(num_features=128)# added batch normalization\n",
    "        #Shape= (64,128,16,16)\n",
    "        self.relu5=nn.ReLU()\n",
    "        #Shape= (64,128,16,16) \n",
    "        \n",
    "        # Defining sixth 2D convolution layer\n",
    "        self.conv6=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (64,256,16,16)\n",
    "        self.bn6=nn.BatchNorm2d(num_features=256)# added batch normalization\n",
    "        #Shape= (64,256,16,16)\n",
    "        self.relu6=nn.ReLU()\n",
    "        #Shape= (64,256,16,16) \n",
    "        \n",
    "        # Defining seventh 2D convolution layer\n",
    "        self.conv7=nn.Conv2d(in_channels=256,out_channels=324,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (64,324,16,16)\n",
    "        self.bn7=nn.BatchNorm2d(num_features=324)# added batch normalization\n",
    "        #Shape= (64,324,16,16)\n",
    "        self.relu7=nn.ReLU()\n",
    "        #Shape= (64,324,16,16) \n",
    "\n",
    "        \n",
    "        self.fc=nn.Linear(in_features=324 * 16 * 16,out_features=num_classes)\n",
    "           \n",
    "        #Feed forwad function\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        \n",
    "        output=self.conv4(output)\n",
    "        output=self.bn4(output)\n",
    "        output=self.relu4(output)\n",
    "        \n",
    "        output=self.conv5(output)\n",
    "        output=self.bn5(output)\n",
    "        output=self.relu5(output)\n",
    "        \n",
    "        output=self.conv6(output)\n",
    "        output=self.bn6(output)\n",
    "        output=self.relu6(output)\n",
    "        \n",
    "        output=self.conv7(output)\n",
    "        output=self.bn7(output)\n",
    "        output=self.relu7(output)\n",
    "    \n",
    "        #Above output will be in matrix form, with shape (64,324,16,16)\n",
    "        output=output.view(-1,324*16*16)\n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparamters Tuning** Two optimizer tried - Adam and SGD and observed better model performance with Adam. and within Adam optimizer lr value fine tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:43.943053Z",
     "iopub.status.busy": "2022-03-25T23:40:43.942509Z",
     "iopub.status.idle": "2022-03-25T23:40:43.968399Z",
     "shell.execute_reply": "2022-03-25T23:40:43.967684Z",
     "shell.execute_reply.started": "2022-03-25T23:40:43.943013Z"
    }
   },
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=4).to(device)\n",
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=lr,weight_decay=0.0001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_function=nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training for 25 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:40:45.508478Z",
     "iopub.status.busy": "2022-03-25T23:40:45.507666Z",
     "iopub.status.idle": "2022-03-25T23:41:42.360054Z",
     "shell.execute_reply": "2022-03-25T23:41:42.359264Z",
     "shell.execute_reply.started": "2022-03-25T23:40:45.508417Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "train_accuracy_arr=[]\n",
    "train_loss_arr=[]\n",
    "val_loss_arr=[]\n",
    "val_accuracy_arr=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    for i, (images,labels) in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss +=loss.item()*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/len(train_dataloader.sampler)\n",
    "    train_loss=train_loss/len(train_dataloader.sampler)\n",
    "    train_accuracy_arr.append(train_accuracy)\n",
    "    train_loss_arr.append(train_loss)\n",
    "    print(train_loss)\n",
    "    \n",
    "    # Evaluation on validation dataset\n",
    "    model.eval()\n",
    "    val_accuracy=0.0\n",
    "    val_loss=0.0\n",
    "    for i, (images,labels) in enumerate(val_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        val_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        val_loss  +=loss.item()*images.size(0)\n",
    "    \n",
    "    val_accuracy=val_accuracy/len(val_dataloader.sampler)\n",
    "    val_loss=val_loss/len(val_dataloader.sampler)\n",
    "    val_loss_arr.append(val_loss)\n",
    "    val_accuracy_arr.append(val_accuracy)\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Validation Accuracy: '+str(val_accuracy))\n",
    "    \n",
    "    #Save the best model with maximum accuracy \n",
    "    if val_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=val_accuracy\n",
    "    \n",
    "print(\"\\nBest Accuracy is :\",best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve the Best Model for label prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:42.362629Z",
     "iopub.status.busy": "2022-03-25T23:41:42.362204Z",
     "iopub.status.idle": "2022-03-25T23:41:42.397995Z",
     "shell.execute_reply": "2022-03-25T23:41:42.397305Z",
     "shell.execute_reply.started": "2022-03-25T23:41:42.362589Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('best_checkpoint.model')\n",
    "model = ConvNet(num_classes=4)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix : Training set** It shows how a classifier is confused while making predictions. The number of True Positives (TPs), False Positives (FPs), True Negatives (TNs) and False Negatives (FNs) for model’s predictions are represented in a N x N matrix where N is the number of labels/classes. It gives an insight on the number and type of errors made by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:42.399627Z",
     "iopub.status.busy": "2022-03-25T23:41:42.399386Z",
     "iopub.status.idle": "2022-03-25T23:41:53.660421Z",
     "shell.execute_reply": "2022-03-25T23:41:53.659710Z",
     "shell.execute_reply.started": "2022-03-25T23:41:42.399593Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in train_dataloader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "for i in range(len(y_true)):\n",
    "    y_true[i]= tr_classes[y_true[i]]\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i]=tr_classes[y_pred[i]]\n",
    "\n",
    "# Build confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,xticks_rotation='vertical') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix : Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:53.663555Z",
     "iopub.status.busy": "2022-03-25T23:41:53.662835Z",
     "iopub.status.idle": "2022-03-25T23:41:55.343415Z",
     "shell.execute_reply": "2022-03-25T23:41:55.342704Z",
     "shell.execute_reply.started": "2022-03-25T23:41:53.663513Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in val_dataloader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "for i in range(len(y_true)):\n",
    "    y_true[i]= val_names[y_true[i]]\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i]=val_names[y_pred[i]]\n",
    "    \n",
    "# Build confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,xticks_rotation='vertical') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss change over epoch** During training, a Loss curve is one of the most commonly used charts to debug a neural network. It provides an overview of the training process as well as\n",
    "the direction in which network learns. In below diagram no overfitting or underfitting observed. Large accuracy in training data and small accuracy in validation data imply overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:55.345881Z",
     "iopub.status.busy": "2022-03-25T23:41:55.345172Z",
     "iopub.status.idle": "2022-03-25T23:41:55.623621Z",
     "shell.execute_reply": "2022-03-25T23:41:55.622924Z",
     "shell.execute_reply.started": "2022-03-25T23:41:55.345827Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_loss_arr, '-o', label=\"train\")\n",
    "plt.plot(val_loss_arr, '-o', label=\"validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss change over epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy change over epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:55.625736Z",
     "iopub.status.busy": "2022-03-25T23:41:55.625074Z",
     "iopub.status.idle": "2022-03-25T23:41:55.899074Z",
     "shell.execute_reply": "2022-03-25T23:41:55.898383Z",
     "shell.execute_reply.started": "2022-03-25T23:41:55.625691Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_accuracy_arr, '-o', label=\"train\")\n",
    "plt.plot(val_accuracy_arr, '-o', label=\"validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy change over epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:55.900767Z",
     "iopub.status.busy": "2022-03-25T23:41:55.900360Z",
     "iopub.status.idle": "2022-03-25T23:41:55.908364Z",
     "shell.execute_reply": "2022-03-25T23:41:55.907601Z",
     "shell.execute_reply.started": "2022-03-25T23:41:55.900729Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:55.910111Z",
     "iopub.status.busy": "2022-03-25T23:41:55.909772Z",
     "iopub.status.idle": "2022-03-25T23:41:55.917646Z",
     "shell.execute_reply": "2022-03-25T23:41:55.916825Z",
     "shell.execute_reply.started": "2022-03-25T23:41:55.910076Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def prediction(image_path,transformer):\n",
    "    image=Image.open(image_path)\n",
    "    image_tensor=transformer(image).float()\n",
    "    image_tensor=image_tensor.unsqueeze_(0)\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()     \n",
    "    input=Variable(image_tensor)\n",
    "    output=model(input)\n",
    "    index=output.data.numpy().argmax()\n",
    "    pred=tr_classes[index]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:41:55.919044Z",
     "iopub.status.busy": "2022-03-25T23:41:55.918715Z",
     "iopub.status.idle": "2022-03-25T23:42:36.091607Z",
     "shell.execute_reply": "2022-03-25T23:42:36.090793Z",
     "shell.execute_reply.started": "2022-03-25T23:41:55.919010Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "test_path = \"/kaggle/input/deep-learning-for-msc-coursework-2022/test/test/\"\n",
    "images_path = glob.glob(test_path+'*.png')\n",
    "\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transform)\n",
    "\n",
    "predict_test = pd.DataFrame(pred_dict.items(), columns=['Id', 'Type'])\n",
    "predict_test.sort_values('Id')\n",
    "\n",
    "compression_opts = dict(method='zip',archive_name='test.csv')  \n",
    "predict_test.sort_values('Id').to_csv('test.zip', index=False,compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AutoEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:42:36.096019Z",
     "iopub.status.busy": "2022-03-25T23:42:36.094656Z",
     "iopub.status.idle": "2022-03-25T23:42:36.103824Z",
     "shell.execute_reply": "2022-03-25T23:42:36.102989Z",
     "shell.execute_reply.started": "2022-03-25T23:42:36.095974Z"
    }
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        #N-batch size, (32*32= 1024)\n",
    "        self.encoder=nn.Sequential(\n",
    "                nn.Linear(32*32,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16,8)#N,8\n",
    "        ) \n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "                nn.Linear(8,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16,32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32,64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64,32*32),#N,32 ->N,1024\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparamter Tuning** Both adam and SGD optimizers used for paramter tuning along with lr value. Adam optimizer with lr =0.000075 had better performance comparitatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:42:36.105405Z",
     "iopub.status.busy": "2022-03-25T23:42:36.105159Z",
     "iopub.status.idle": "2022-03-25T23:42:36.121065Z",
     "shell.execute_reply": "2022-03-25T23:42:36.120301Z",
     "shell.execute_reply.started": "2022-03-25T23:42:36.105367Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=0.0001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model using AutoEncoder for 10 epochs and evaluated on validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:42:36.123175Z",
     "iopub.status.busy": "2022-03-25T23:42:36.122666Z",
     "iopub.status.idle": "2022-03-25T23:42:36.127642Z",
     "shell.execute_reply": "2022-03-25T23:42:36.126903Z",
     "shell.execute_reply.started": "2022-03-25T23:42:36.123138Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs=10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:42:36.130347Z",
     "iopub.status.busy": "2022-03-25T23:42:36.130144Z",
     "iopub.status.idle": "2022-03-25T23:42:59.860855Z",
     "shell.execute_reply": "2022-03-25T23:42:59.859907Z",
     "shell.execute_reply.started": "2022-03-25T23:42:36.130317Z"
    }
   },
   "outputs": [],
   "source": [
    "training_loss_min=np.Inf\n",
    "train_loss_arr=[]\n",
    "val_loss_arr=[]\n",
    "train_acc_arr=[]\n",
    "val_acc_arr=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
    "    epoch_arr.append(epoch)\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    train_accuracy=0.0\n",
    "    #training model on Training set\n",
    "    for i, (images,labels) in tqdm(enumerate(train_dataloader), total=int(len(train_dataloader)/train_dataloader.batch_size)):\n",
    "        images = images.to(device) \n",
    "        images = images.reshape(-1,32*32)\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction= model(images)\n",
    "        loss = criterion(reconstruction, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "        _,prediction=torch.max(reconstruction.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==prediction.data))\n",
    "    \n",
    "    train_accuracy = train_accuracy/len(train_dataloader.sampler)\n",
    "    train_loss = running_loss/len(train_dataloader.sampler)\n",
    "    train_loss_arr.append(np.round(train_loss,6))\n",
    "    train_acc_arr.append(train_accuracy)\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss=0.0\n",
    "    val_accuracy=0.0\n",
    "    #evaluation on validation set\n",
    "    for i, (images,labels) in tqdm(enumerate(val_dataloader), total=int(len(val_dataloader)/val_dataloader.batch_size)):\n",
    "        images = images.to(device)\n",
    "        images = images.reshape(-1,32*32)\n",
    "        reconstruction = model(images)\n",
    "        loss = criterion(reconstruction, images)\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "        _,prediction=torch.max(reconstruction.data,1)\n",
    "        val_accuracy+=int(torch.sum(prediction==prediction.data))\n",
    "   \n",
    "    val_loss = running_loss/len(val_dataloader.sampler)\n",
    "    val_loss_arr.append(np.round(val_loss,6))\n",
    "    val_accuracy = val_accuracy/len(train_dataloader.sampler)\n",
    "    val_acc_arr.append(np.round(val_accuracy,6))\n",
    "        \n",
    "    print(\"Train Loss: \",train_loss, \" Validation Loss: \",val_loss)\n",
    "    \n",
    "    # save model if training loss has decreased\n",
    "    if train_loss<=training_loss_min:\n",
    "        torch.save(model.state_dict(),'best_checkpoint_auto.model')\n",
    "        training_loss_min=train_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saved the checkpoint where model has minimum loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:42:59.862870Z",
     "iopub.status.busy": "2022-03-25T23:42:59.862486Z",
     "iopub.status.idle": "2022-03-25T23:42:59.881311Z",
     "shell.execute_reply": "2022-03-25T23:42:59.880620Z",
     "shell.execute_reply.started": "2022-03-25T23:42:59.862813Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('best_checkpoint_auto.model')\n",
    "model = AutoEncoder().to(device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss change over epoch (Training and Validation Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:42:59.883027Z",
     "iopub.status.busy": "2022-03-25T23:42:59.882737Z",
     "iopub.status.idle": "2022-03-25T23:43:00.178466Z",
     "shell.execute_reply": "2022-03-25T23:43:00.177746Z",
     "shell.execute_reply.started": "2022-03-25T23:42:59.882982Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_loss_arr, '-o', label=\"Train Loss\")\n",
    "plt.plot(val_loss_arr, '-o', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss change over epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:43:00.180447Z",
     "iopub.status.busy": "2022-03-25T23:43:00.179692Z",
     "iopub.status.idle": "2022-03-25T23:43:00.190149Z",
     "shell.execute_reply": "2022-03-25T23:43:00.189466Z",
     "shell.execute_reply.started": "2022-03-25T23:43:00.180405Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_loop(model, device, test_loader):\n",
    "    #model.eval()\n",
    "    model = model.to(device)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.reshape(-1,32*32)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data)\n",
    "            print(loss)\n",
    "            test_loss += loss.item()*images.size(0)  # sum up batch loss\n",
    "            print(test_loss)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "#test_loop(model,device,test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Submission**\n",
    "Model is trained on entire train set (1700 cell images) for 25 epochs with fine tuned paramters and predict on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:43:00.191817Z",
     "iopub.status.busy": "2022-03-25T23:43:00.191335Z",
     "iopub.status.idle": "2022-03-25T23:43:00.199872Z",
     "shell.execute_reply": "2022-03-25T23:43:00.199171Z",
     "shell.execute_reply.started": "2022-03-25T23:43:00.191777Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "num_epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:43:00.201323Z",
     "iopub.status.busy": "2022-03-25T23:43:00.200986Z",
     "iopub.status.idle": "2022-03-25T23:43:00.226928Z",
     "shell.execute_reply": "2022-03-25T23:43:00.226290Z",
     "shell.execute_reply.started": "2022-03-25T23:43:00.201282Z"
    }
   },
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=4).to(device)\n",
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=lr,weight_decay=0.0001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:43:00.228712Z",
     "iopub.status.busy": "2022-03-25T23:43:00.228258Z",
     "iopub.status.idle": "2022-03-25T23:44:16.311103Z",
     "shell.execute_reply": "2022-03-25T23:44:16.309642Z",
     "shell.execute_reply.started": "2022-03-25T23:43:00.228676Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "train_accuracy_arr=[]\n",
    "train_loss_arr=[]\n",
    "val_loss_arr=[]\n",
    "val_accuracy_arr=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    for i, (images,labels) in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss +=loss.item()*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/len(train_dataloader.sampler)\n",
    "    train_loss=train_loss/len(train_dataloader.sampler)\n",
    "    train_accuracy_arr.append(train_accuracy)\n",
    "    train_loss_arr.append(train_loss)\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if train_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint_final.model')\n",
    "        best_accuracy=train_accuracy\n",
    "    \n",
    "print(\"\\nBest Accuracy is :\",best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:44:16.312942Z",
     "iopub.status.busy": "2022-03-25T23:44:16.312631Z",
     "iopub.status.idle": "2022-03-25T23:44:16.343952Z",
     "shell.execute_reply": "2022-03-25T23:44:16.343095Z",
     "shell.execute_reply.started": "2022-03-25T23:44:16.312903Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('best_checkpoint_final.model')\n",
    "model = ConvNet(num_classes=4)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix : Entire Training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:44:16.345843Z",
     "iopub.status.busy": "2022-03-25T23:44:16.345547Z",
     "iopub.status.idle": "2022-03-25T23:44:29.958336Z",
     "shell.execute_reply": "2022-03-25T23:44:29.957660Z",
     "shell.execute_reply.started": "2022-03-25T23:44:16.345807Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in train_dataloader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "for i in range(len(y_true)):\n",
    "    y_true[i]= tr_classes[y_true[i]]\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i]=tr_classes[y_pred[i]]\n",
    "\n",
    "# Build confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred,xticks_rotation='vertical') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss and Accuracy over epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:44:29.961247Z",
     "iopub.status.busy": "2022-03-25T23:44:29.959600Z",
     "iopub.status.idle": "2022-03-25T23:44:30.244434Z",
     "shell.execute_reply": "2022-03-25T23:44:30.243688Z",
     "shell.execute_reply.started": "2022-03-25T23:44:29.961205Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_loss_arr, '-o', label=\"Train Loss\")\n",
    "plt.plot(train_accuracy_arr, '-o', label=\"Train Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss and Accuracy change over epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:44:30.246504Z",
     "iopub.status.busy": "2022-03-25T23:44:30.246037Z",
     "iopub.status.idle": "2022-03-25T23:44:30.253899Z",
     "shell.execute_reply": "2022-03-25T23:44:30.253201Z",
     "shell.execute_reply.started": "2022-03-25T23:44:30.246466Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:44:30.256704Z",
     "iopub.status.busy": "2022-03-25T23:44:30.256154Z",
     "iopub.status.idle": "2022-03-25T23:44:30.263170Z",
     "shell.execute_reply": "2022-03-25T23:44:30.262456Z",
     "shell.execute_reply.started": "2022-03-25T23:44:30.256666Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def prediction(image_path,transformer):\n",
    "    image=Image.open(image_path)\n",
    "    image_tensor=transformer(image).float()\n",
    "    image_tensor=image_tensor.unsqueeze_(0)\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()     \n",
    "    input=Variable(image_tensor)\n",
    "    output=model(input)\n",
    "    index=output.data.numpy().argmax()\n",
    "    pred=tr_classes[index]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:44:30.265361Z",
     "iopub.status.busy": "2022-03-25T23:44:30.264744Z",
     "iopub.status.idle": "2022-03-25T23:45:00.043564Z",
     "shell.execute_reply": "2022-03-25T23:45:00.042822Z",
     "shell.execute_reply.started": "2022-03-25T23:44:30.265323Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "test_path = \"/kaggle/input/deep-learning-for-msc-coursework-2022/test/test/\"\n",
    "images_path = glob.glob(test_path+'*.png')\n",
    "\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transform)\n",
    "\n",
    "predict_test = pd.DataFrame(pred_dict.items(), columns=['Id', 'Type'])\n",
    "predict_test.sort_values('Id')\n",
    "\n",
    "compression_opts = dict(method='zip',archive_name='test.csv')  \n",
    "predict_test.sort_values('Id').to_csv('test.zip', index=False,compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label distribution based on the prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T23:45:00.044942Z",
     "iopub.status.busy": "2022-03-25T23:45:00.044681Z",
     "iopub.status.idle": "2022-03-25T23:45:00.232400Z",
     "shell.execute_reply": "2022-03-25T23:45:00.231707Z",
     "shell.execute_reply.started": "2022-03-25T23:45:00.044907Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test['Type'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Test Set label Prediction\")\n",
    "plt.xlabel(\"Cell Type\")\n",
    "plt.ylabel(\"Number of cells\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
